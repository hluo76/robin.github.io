---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

* # Question Classification with Deep Contextualized Transformer 
## Haozheng Luo, Ningwei Liu, Charles Feng – FICC 2021: https://arxiv.org/abs/1910.10492
FICC is a conference hold by the Science and Information Organization, the conference was well attended by 200+ delegates. The conference comprised of 5 keynote talks by esteemed speakers, 134 papers presentations and 9 poster presentations in 2020.<br />
Abstract: Recent literature has focused on the Standford Parse Tree and how it has been used for Question and Answer problems in Natural Language Processing. This parser tree with deep learning algorithms has analyzed the makeup of question and answer classifications. In this study, the authors have built a model using a Deep Contextualized Transformer that can manage some aberrant expressions. We conducted extensive evaluations on SQuAD and SwDA datasets and our model showed sig- nificant improvements to QA problem classifications for industry needs. Further analysis investigated the impact of various models on the accu- racy of the results. Research outcomes showed that our new method is more effective in solving QA problems with a higher accuracy of up to 83.1% compared to other models.
* # Differentiable End-to-End Program Executor for Sample and Computationally Efficient VQA  
## Karan Samel*, Zelin Zhao*, Kuan Wang*, Haozheng Luo, Binghong Chen, Song Le – ICLM 2021 (Under Review) <br />https://paperswithcode.com/paper/differentiable-end-to-end-program-executor
+First Author with the equal contribution<br />
Abstract: We present a differentiable end-to-end program executor (DePe), which addresses Visual Question Answering (VQA) in a sample and computationally efficient manner. DePe parses the question into probabilistic programs and softly executes them to acquire the final answer. These functional programs adopt soft-logic functions to enable approximate probabilistic logic reasoning. In addition to the language, DePe also jointly learns visual object-centric representations in an end-to-end manner. We demonstrate through extensive experiments that DePe is more sample and computationally efficient than other VQA methodologies while retaining state-of-the-art performance.
